{"url":"/docs/highlighting/parallel/","title":"Parallel Processing","description":"Highlight multiple code blocks concurrently with highlight_many()","plain_text":"Parallel Processing For sites with many code blocks, highlight_many() provides concurrent processing with 1.5-2x speedup on Python 3.14t. When to Use Scenario Recommendation &lt; 8 blocks Use highlight() in a loop 8+ blocks Use highlight_many() 50+ blocks on 3.14t Significant speedup The overhead of thread management makes highlight_many() slower for small batches. Rosettes automatically falls back to sequential processing for &lt; 8 blocks. highlight_many() Highlight multiple code blocks in parallel. from rosettes import highlight_many blocks = [ (&quot;def foo(): pass&quot;, &quot;python&quot;), (&quot;const x = 1;&quot;, &quot;javascript&quot;), (&quot;fn main() {}&quot;, &quot;rust&quot;), (&#x27;{&quot;key&quot;: &quot;value&quot;}&#x27;, &quot;json&quot;), ] results = highlight_many(blocks) # Returns list of HTML strings in same order as input Parameters Parameter Type Default Description items Iterable[tuple[str, str]] required (code, language) tuples max_workers int min(4, cpu_count) Thread count css_class_style str &quot;semantic&quot; &quot;semantic&quot; or &quot;pygments&quot; Worker Count The default of 4 workers is optimal based on benchmarking: # Default: 4 workers (optimal) results = highlight_many(blocks) # Custom worker count results = highlight_many(blocks, max_workers=8) Note Note More workers doesn't always mean faster. Thread overhead and memory contention can reduce performance beyond 4-8 workers. tokenize_many() Parallel tokenization for raw token access. from rosettes import tokenize_many blocks = [ (&quot;x = 1&quot;, &quot;python&quot;), (&quot;let y = 2;&quot;, &quot;javascript&quot;), ] results = tokenize_many(blocks) # Returns list of token lists for i, tokens in enumerate(results): print(f&quot;Block {i}: {len(tokens)} tokens&quot;) Free-Threading Performance On Python 3.14t with free-threading enabled (PEP 703), highlight_many() provides true parallelism: Blocks GIL Python Free-Threading Speedup 10 15ms 12ms 1.25x 50 75ms 42ms 1.78x 100 150ms 78ms 1.92x Why It Works Rosettes is thread-safe by design: Immutable tokens: Token is a NamedTuple Local-only state: Lexers use only local variables during tokenization No shared mutable data: No global state to contend for PEP 703 declaration: Module declares itself safe for free-threading Example: Static Site Generator from rosettes import highlight_many from pathlib import Path def highlight_all_code_blocks(pages: list[dict]) -&gt; list[dict]: &quot;&quot;&quot;Highlight all code blocks across all pages.&quot;&quot;&quot; # Collect all code blocks blocks = [] block_locations = [] # Track which page/block each belongs to for page_idx, page in enumerate(pages): for block_idx, block in enumerate(page[&quot;code_blocks&quot;]): blocks.append((block[&quot;code&quot;], block[&quot;language&quot;])) block_locations.append((page_idx, block_idx)) # Highlight in parallel results = highlight_many(blocks) # Assign results back to pages for (page_idx, block_idx), html in zip(block_locations, results): pages[page_idx][&quot;code_blocks&quot;][block_idx][&quot;html&quot;] = html return pages Next Steps Thread Safety — How Rosettes achieves thread safety Performance — Benchmarks and optimization tips","excerpt":"Parallel Processing For sites with many code blocks, highlight_many() provides concurrent processing with 1.5-2x speedup on Python 3.14t. When to Use Scenario Recommendation < 8 blocks Use...","metadata":{"title":"Parallel Processing","description":"Highlight multiple code blocks concurrently with highlight_many()","draft":false,"weight":20,"lang":"en","type":"doc","tags":["parallel","performance"],"keywords":["highlight_many","parallel","concurrent","free-threading"],"icon":"cpu","variant":"standard"},"section":"highlighting","tags":["parallel","performance"],"word_count":391,"reading_time":2,"graph":{"nodes":[{"id":"-2680059364504895038","label":"Highlighting","url":"/docs/highlighting/","type":"regular","tags":["highlighting","api"],"incoming_refs":6,"outgoing_refs":5,"connectivity":11,"reading_time":1,"size":25.3,"color":"var(--graph-node-regular)","isCurrent":true},{"id":"-6014002478458981531","label":"Basic Usage","url":"/docs/highlighting/basic-usage/","type":"regular","tags":["highlighting","api"],"incoming_refs":4,"outgoing_refs":5,"connectivity":9,"reading_time":2,"size":23.1,"color":"var(--graph-node-regular)","isCurrent":true},{"id":"3146124063214178861","label":"Performance","url":"/docs/about/performance/","type":"regular","tags":["performance","benchmarks"],"incoming_refs":4,"outgoing_refs":3,"connectivity":7,"reading_time":3,"size":20.9,"color":"var(--graph-node-regular)","isCurrent":true},{"id":"4241832673428245673","label":"Line Highlighting","url":"/docs/highlighting/line-highlighting/","type":"regular","tags":["highlighting","lines"],"incoming_refs":4,"outgoing_refs":3,"connectivity":7,"reading_time":2,"size":20.1,"color":"var(--graph-node-regular)","isCurrent":true},{"id":"-106756179683539329","label":"Parallel Processing","url":"/docs/highlighting/parallel/","type":"regular","tags":["parallel","performance"],"incoming_refs":4,"outgoing_refs":3,"connectivity":7,"reading_time":2,"size":20.1,"color":"var(--graph-node-regular)","isCurrent":true}],"edges":[{"source":"3146124063214178861","target":"-106756179683539329","weight":2},{"source":"-2680059364504895038","target":"-106756179683539329","weight":1},{"source":"-6014002478458981531","target":"-106756179683539329","weight":2},{"source":"4241832673428245673","target":"-106756179683539329","weight":2}]}}